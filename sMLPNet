from torch import nn
from torch.nn import functional as F
import os  # 导入os模块，用于文件和目录操作
import torch  # 导入torch库，用于构建神经网络
import torchvision  # 导入torchvision库，用于数据集和预训练模型
from torch.utils.data import DataLoader  # 导入DataLoader，用于加载数据
from torchvision import datasets, transforms  # 导入torchvision的datasets和transforms模块，用于数据集和数据转换
import logging  # 导入logging模块，用于日志记录
import random  # 导入random模块，用于固定随机种子
import numpy as np  # 导入numpy模块，用于固定随机种子
import torch.optim as optim  # 导入优化器模块
from einops.layers.torch import Rearrange  # 导入Rearrange层
from timm.models.layers import DropPath  # 导入DropPath层

class FeedForward(nn.Module):
    def __init__(self, dim, hidden_dim, dropout=0.):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, dim),
            nn.Dropout(dropout)
        )

    def forward(self, x):
        return self.net(x)


class BN_Activ_Conv(nn.Module):
    def __init__(self, in_channels, activation, out_channels, kernel_size, stride=(1, 1), dilation=(1, 1), groups=1):
        super(BN_Activ_Conv, self).__init__()
        self.BN = nn.BatchNorm2d(out_channels)
        self.Activation = activation
        padding = [int((dilation[j] * (kernel_size[j] - 1) - stride[j] + 1) / 2) for j in range(2)]  # Same padding
        self.Conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups=groups, bias=False)

    def forward(self, img):
        img = self.BN(img)
        img = self.Activation(img)
        img = self.Conv(img)
        return img


class sMLPBlock(nn.Module):
    def __init__(self, W, H, channels):
        super().__init__()
        assert W == H
        self.channels = channels
        self.activation = nn.GELU()
        self.BN = nn.BatchNorm2d(channels)
        self.proj_h = nn.Conv2d(H, H, (1, 1))
        self.proh_w = nn.Conv2d(W, W, (1, 1))
        self.fuse = nn.Conv2d(channels*3, channels, (1,1), (1,1), bias=False)

    def forward(self, x):
        x = self.activation(self.BN(x))
        x_h = self.proj_h(x.permute(0, 3, 1, 2)).permute(0, 2, 3, 1)
        x_w = self.proh_w(x.permute(0, 2, 1, 3)).permute(0, 2, 1, 3)
        x = self.fuse(torch.cat([x, x_h, x_w], dim=1))
        return x


class DWConvBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.conv_merge = BN_Activ_Conv(channels, nn.GELU(), channels, (3, 3), groups=channels)

    def forward(self, img):
        img = self.conv_merge(img)
        return img


class sMLPNet(nn.Module):

    def __init__(self, in_chans=3, dim=80, alpha=3, num_classes=1000, patch_size=4, image_size=224, depths=[2,8,14,2], dp_rate=0.,
                 **kwargs):
        super(sMLPNet, self).__init__()
        '''
        (B,H,W,C): (B,(image_size// patch_size)**2,dim)
        '''

        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'
        self.num_patch = image_size // patch_size
        self.depths = depths

        self.to_patch_embedding = nn.ModuleList([])
        self.token_mix = nn.ModuleList([])
        self.channel_mix = nn.ModuleList([])
        self.drop_path = nn.ModuleList([])

        net_num_blocks = sum(self.depths)
        net_block_idx = 0
        for i in range(len(self.depths)):
            ratio = 2 ** i
            if i == 0:
                self.to_patch_embedding.append(nn.Sequential(nn.Conv2d(in_chans, dim, patch_size, patch_size, bias=False)))
            else:
                self.to_patch_embedding.append(nn.Sequential(nn.Conv2d(dim * ratio // 2, dim * ratio, 2, 2, bias=False)))

            for j in range(self.depths[i]):
                block_dpr = dp_rate * net_block_idx / (net_num_blocks - 1)  # stochastic depth linear decay rule
                self.drop_path.append(DropPath(block_dpr) if block_dpr > 0. else nn.Identity())
                net_block_idx += 1

                self.channel_mix.append(nn.Sequential(
                                     Rearrange('b c h w -> b h w c'),
                                     nn.LayerNorm(dim*ratio),
                                     FeedForward(dim*ratio,dim*ratio*alpha),
                                     Rearrange('b h w c -> b c h w'))
                                     )

                self.token_mix.append(nn.Sequential(DWConvBlock(dim*ratio), sMLPBlock(self.num_patch//ratio, self.num_patch//ratio, dim * ratio)))

        self.batch_norm = nn.BatchNorm2d(dim*2**(len(self.depths)-1))

        self.mlp_head = nn.Sequential(
            nn.Linear(dim * 2**(len(self.depths)-1), num_classes)
        )

    def forward(self, x):

        shift = 0
        for i in range(len(self.depths)):
            x = self.to_patch_embedding[i](x)
            for j in range(self.depths[i]):
                x = x + self.drop_path[j+shift](self.token_mix[j+shift](x))
                x = x + self.drop_path[j+shift](self.channel_mix[j+shift](x))
            shift += self.depths[i]

        x = self.batch_norm(x)

        x = x.mean(dim=[2,3]).flatten(1)

        return self.mlp_head(x)


def check_sizes(image_size, patch_size):
    sqrt_num_patches, remainder = divmod(image_size, patch_size)
    assert remainder == 0, "`image_size` must be divisible by `patch_size`"
    num_patches = sqrt_num_patches ** 2
    return num_patches


def main():
    # 固定随机种子以保证结果可复现性
    seed = 42
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

    # 设置日志记录
    logging.basicConfig(filename='training.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    # 定义运行设备
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logging.info(f'使用设备: {device}')

    # 数据预处理
    transform = transforms.Compose([
        transforms.Resize((224, 224)),  # 调整图像大小为 224x224
        transforms.ToTensor(),  # 将图像转换为张量
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化图像
    ])

    # 加载数据集
    train_dataset = datasets.ImageFolder(root=r'D:\resnet\supervised_fault_classification\defect_supervised\glass-insulator\train', transform=transform)
    val_dataset = datasets.ImageFolder(root=r'D:\resnet\supervised_fault_classification\defect_supervised\glass-insulator\val', transform=transform)

    # 创建数据加载器
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    # 定义模型
    model = sMLPNet(image_size=224, patch_size=4, in_channels=3, num_features=80, expansion_factor=3,
                    num_layers=sum([2, 8, 14, 2]), num_classes=len(train_dataset.classes), dp_rate=0.5)
    model.to(device)
    logging.info('模型已初始化')

    # 定义损失函数和优化器
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    logging.info('损失函数和优化器已设置')

    # 训练循环
    num_epochs = 1

    best_val_acc = 0.0

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct_train = 0
        total_train = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()

        epoch_loss = running_loss / total_train
        epoch_acc = correct_train / total_train

        logging.info(f'Epoch [{epoch + 1}/{num_epochs}], 训练损失: {epoch_loss:.4f}, 训练准确率: {epoch_acc:.4f}')
        print(f'Epoch [{epoch + 1}/{num_epochs}], 训练损失: {epoch_loss:.4f}, 训练准确率: {epoch_acc:.4f}')

        # 验证
        model.eval()
        correct_val = 0
        total_val = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)

                outputs = model(inputs)
                _, predicted = torch.max(outputs.data, 1)
                total_val += labels.size(0)
                correct_val += (predicted == labels).sum().item()

        epoch_val_acc = correct_val / total_val
        logging.info(f'Epoch [{epoch + 1}/{num_epochs}], 验证准确率: {epoch_val_acc:.4f}')
        print(f'Epoch [{epoch + 1}/{num_epochs}], 验证准确率: {epoch_val_acc:.4f}')

        # 保存最佳模型
        if epoch_val_acc > best_val_acc:
            best_val_acc = epoch_val_acc
            checkpoint_path = f'model_epoch_{epoch + 1}_acc_{epoch_val_acc:.4f}.pth'
            torch.save(model.state_dict(), checkpoint_path)
            logging.info(f'保存最佳模型到 {checkpoint_path}')

    print('训练完成')

if __name__ == "__main__":
    main()


